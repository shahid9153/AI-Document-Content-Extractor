ğŸ“˜ Smart AI Document Content Extractor

ğŸš€ An intelligent document analysis tool powered by Google Gemini 2.5 Flash and LangChain.
Upload any PDF and instantly get summaries, insights, and AI-powered answers â€” all within an elegant Streamlit interface.

ğŸ§© Overview

Smart AI Document Content Extractor is a lightweight, powerful application built using LangChain, Gemini 2.5 Flash, and FAISS vector search.

It allows you to:

ğŸ“‚ Upload PDF documents

ğŸ§  Automatically extract and chunk the text

ğŸ—‚ï¸ Store embeddings in a FAISS vector database

âœ¨ Generate AI-driven summaries

ğŸ’¬ Ask natural language questions about the content

All powered by Googleâ€™s Gemini 2.5 Flash model for lightning-fast and accurate responses.

ğŸ¯ Features
Feature	Description
ğŸ“¤ PDF Upload	Upload any PDF file through a simple drag-and-drop interface
ğŸ§  Smart Summarization	Get a detailed summary of the uploaded document in seconds
ğŸ’¬ Question Answering	Ask context-aware questions about your PDF
âš¡ Gemini 2.5 Flash	Utilizes Googleâ€™s latest multimodal LLM for speed and accuracy
ğŸ§® FAISS Vector Search	Enables efficient semantic retrieval of document chunks
ğŸ¨ Modern Streamlit UI	Clean, responsive, and professional design
ğŸ” Secure API Handling	Uses environment variables to protect API keys
ğŸ—ï¸ Tech Stack
Component	Technology
Frontend	Streamlit
Backend AI	LangChain + Gemini 2.5 Flash
Vector Store	FAISS
Embeddings	HuggingFace Sentence Transformers
Environment Management	python-dotenv
PDF Parsing	PyPDF via LangChain loaders
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/smart-ai-document-extractor.git
cd smart-ai-document-extractor

2ï¸âƒ£ Create a Virtual Environment
python -m venv venv
venv\Scripts\activate     # For Windows
source venv/bin/activate  # For macOS/Linux

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Your Gemini API Key

Create a .env file in the project root:

GEMINI_API_KEY=your_gemini_flash_2_5_key_here


ğŸ’¡ Donâ€™t expose your API key publicly â€” keep .env private!

5ï¸âƒ£ Run the App
streamlit run app.py

ğŸ–¥ï¸ Usage Guide
â–¶ï¸ Step 1: Launch the App

Once you run the app, Streamlit will open a local browser window (usually at http://localhost:8501).

ğŸ“¤ Step 2: Upload a PDF

Upload your document using the file uploader. The app will:

Extract text

Split it into chunks

Create vector embeddings

ğŸ§¾ Step 3: Generate Summary

Click "âœ¨ Generate Summary" to view an AI-generated summary of the document.

ğŸ’¬ Step 4: Ask Questions

Type your question in the input box (e.g., â€œWhat is the conclusion of this report?â€) and hit Ask AI to get contextual answers.

ğŸ“ Project Structure
ğŸ“ Smart-AI-Document-Extractor/
â”‚
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ .env                   # Contains GEMINI_API_KEY
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation

ğŸ§  How It Works (Simplified Flow)

Load PDF â†’ Using PyPDFLoader from LangChain

Split & Embed â†’ Convert chunks to vector embeddings using HuggingFaceEmbeddings

Store in FAISS â†’ For quick semantic retrieval

Query + RAG â†’ Combine retrieved chunks + Gemini model for context-aware answers

Output â†’ Display summarized or queried results in Streamlit UI

ğŸ–Œï¸ UI Preview (Example)
ğŸ“˜ Smart AI Document Content Extractor
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“‚ Upload PDF: [Choose File]
âœ… PDF loaded successfully with 25 chunks

âœ¨ Generate Summary
ğŸ§¾ Document Summary:
â€¢ The document discusses renewable energy...
â€¢ Key points include cost efficiency and storage...

ğŸ’¬ Ask Questions:
[ What are the challenges of solar adoption? ]
â†’ The main challenges include cost, policy, and awareness.

ğŸš€ Future Improvements

ğŸ“Š Extract structured data tables from PDFs

ğŸ—£ï¸ Support for multimodal input (image + text)

ğŸŒ Cloud deployment on Streamlit Cloud or Hugging Face Spaces

ğŸ§© Chat history memory and follow-up context
